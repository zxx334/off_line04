{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.571428571428571,
  "eval_steps": 500,
  "global_step": 50,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.07142857142857142,
      "grad_norm": 3.0582993030548096,
      "learning_rate": 0.001,
      "loss": 4.0767,
      "step": 1
    },
    {
      "epoch": 0.14285714285714285,
      "grad_norm": 2.9908642768859863,
      "learning_rate": 0.0009857142857142857,
      "loss": 4.0234,
      "step": 2
    },
    {
      "epoch": 0.21428571428571427,
      "grad_norm": 3.4664692878723145,
      "learning_rate": 0.0009714285714285714,
      "loss": 4.0673,
      "step": 3
    },
    {
      "epoch": 0.2857142857142857,
      "grad_norm": 3.131868839263916,
      "learning_rate": 0.0009571428571428573,
      "loss": 3.9113,
      "step": 4
    },
    {
      "epoch": 0.35714285714285715,
      "grad_norm": 3.3775808811187744,
      "learning_rate": 0.0009428571428571429,
      "loss": 3.8742,
      "step": 5
    },
    {
      "epoch": 0.42857142857142855,
      "grad_norm": 4.2891716957092285,
      "learning_rate": 0.0009285714285714287,
      "loss": 3.9903,
      "step": 6
    },
    {
      "epoch": 0.5,
      "grad_norm": 3.7851247787475586,
      "learning_rate": 0.0009142857142857143,
      "loss": 3.8026,
      "step": 7
    },
    {
      "epoch": 0.5714285714285714,
      "grad_norm": 4.328288555145264,
      "learning_rate": 0.0009000000000000001,
      "loss": 3.7909,
      "step": 8
    },
    {
      "epoch": 0.6428571428571429,
      "grad_norm": 4.339515209197998,
      "learning_rate": 0.0008857142857142857,
      "loss": 3.6869,
      "step": 9
    },
    {
      "epoch": 0.7142857142857143,
      "grad_norm": 5.907003879547119,
      "learning_rate": 0.0008714285714285715,
      "loss": 3.8811,
      "step": 10
    },
    {
      "epoch": 0.7857142857142857,
      "grad_norm": 5.321662425994873,
      "learning_rate": 0.0008571428571428571,
      "loss": 3.763,
      "step": 11
    },
    {
      "epoch": 0.8571428571428571,
      "grad_norm": 5.649955749511719,
      "learning_rate": 0.0008428571428571429,
      "loss": 3.7206,
      "step": 12
    },
    {
      "epoch": 0.9285714285714286,
      "grad_norm": 6.377830505371094,
      "learning_rate": 0.0008285714285714286,
      "loss": 3.7104,
      "step": 13
    },
    {
      "epoch": 1.0,
      "grad_norm": 7.02921724319458,
      "learning_rate": 0.0008142857142857143,
      "loss": 3.6756,
      "step": 14
    },
    {
      "epoch": 1.0714285714285714,
      "grad_norm": 6.843153476715088,
      "learning_rate": 0.0008,
      "loss": 3.6038,
      "step": 15
    },
    {
      "epoch": 1.1428571428571428,
      "grad_norm": 6.549403190612793,
      "learning_rate": 0.0007857142857142857,
      "loss": 3.4659,
      "step": 16
    },
    {
      "epoch": 1.2142857142857142,
      "grad_norm": 6.383352756500244,
      "learning_rate": 0.0007714285714285715,
      "loss": 3.4266,
      "step": 17
    },
    {
      "epoch": 1.2857142857142856,
      "grad_norm": 7.633579730987549,
      "learning_rate": 0.0007571428571428572,
      "loss": 3.444,
      "step": 18
    },
    {
      "epoch": 1.3571428571428572,
      "grad_norm": 8.90324878692627,
      "learning_rate": 0.0007428571428571429,
      "loss": 3.4496,
      "step": 19
    },
    {
      "epoch": 1.4285714285714286,
      "grad_norm": 8.668672561645508,
      "learning_rate": 0.0007285714285714286,
      "loss": 3.3393,
      "step": 20
    },
    {
      "epoch": 1.5,
      "grad_norm": 8.451957702636719,
      "learning_rate": 0.0007142857142857143,
      "loss": 3.2751,
      "step": 21
    },
    {
      "epoch": 1.5714285714285714,
      "grad_norm": 8.05207633972168,
      "learning_rate": 0.0007,
      "loss": 3.1742,
      "step": 22
    },
    {
      "epoch": 1.6428571428571428,
      "grad_norm": 9.801552772521973,
      "learning_rate": 0.0006857142857142857,
      "loss": 3.1664,
      "step": 23
    },
    {
      "epoch": 1.7142857142857144,
      "grad_norm": 7.704885959625244,
      "learning_rate": 0.0006714285714285714,
      "loss": 3.0117,
      "step": 24
    },
    {
      "epoch": 1.7857142857142856,
      "grad_norm": 7.627701759338379,
      "learning_rate": 0.0006571428571428571,
      "loss": 3.0027,
      "step": 25
    },
    {
      "epoch": 1.8571428571428572,
      "grad_norm": 9.427223205566406,
      "learning_rate": 0.0006428571428571429,
      "loss": 2.983,
      "step": 26
    },
    {
      "epoch": 1.9285714285714286,
      "grad_norm": 7.939276218414307,
      "learning_rate": 0.0006285714285714285,
      "loss": 2.8924,
      "step": 27
    },
    {
      "epoch": 2.0,
      "grad_norm": 9.076739311218262,
      "learning_rate": 0.0006142857142857143,
      "loss": 2.8715,
      "step": 28
    },
    {
      "epoch": 2.0714285714285716,
      "grad_norm": 9.33159351348877,
      "learning_rate": 0.0006,
      "loss": 2.7909,
      "step": 29
    },
    {
      "epoch": 2.142857142857143,
      "grad_norm": 9.694365501403809,
      "learning_rate": 0.0005857142857142858,
      "loss": 2.7253,
      "step": 30
    },
    {
      "epoch": 2.2142857142857144,
      "grad_norm": 8.399603843688965,
      "learning_rate": 0.0005714285714285714,
      "loss": 2.7023,
      "step": 31
    },
    {
      "epoch": 2.2857142857142856,
      "grad_norm": 11.5150146484375,
      "learning_rate": 0.0005571428571428572,
      "loss": 2.6233,
      "step": 32
    },
    {
      "epoch": 2.357142857142857,
      "grad_norm": 9.715849876403809,
      "learning_rate": 0.0005428571428571428,
      "loss": 2.573,
      "step": 33
    },
    {
      "epoch": 2.4285714285714284,
      "grad_norm": 11.553606986999512,
      "learning_rate": 0.0005285714285714286,
      "loss": 2.5475,
      "step": 34
    },
    {
      "epoch": 2.5,
      "grad_norm": 8.458468437194824,
      "learning_rate": 0.0005142857142857142,
      "loss": 2.4925,
      "step": 35
    },
    {
      "epoch": 2.571428571428571,
      "grad_norm": 8.45255184173584,
      "learning_rate": 0.0005,
      "loss": 2.4435,
      "step": 36
    },
    {
      "epoch": 2.642857142857143,
      "grad_norm": 12.008199691772461,
      "learning_rate": 0.0004857142857142857,
      "loss": 2.3657,
      "step": 37
    },
    {
      "epoch": 2.7142857142857144,
      "grad_norm": 9.262848854064941,
      "learning_rate": 0.0004714285714285714,
      "loss": 2.3624,
      "step": 38
    },
    {
      "epoch": 2.7857142857142856,
      "grad_norm": 8.579690933227539,
      "learning_rate": 0.00045714285714285713,
      "loss": 2.2798,
      "step": 39
    },
    {
      "epoch": 2.857142857142857,
      "grad_norm": 10.268279075622559,
      "learning_rate": 0.00044285714285714284,
      "loss": 2.2639,
      "step": 40
    },
    {
      "epoch": 2.928571428571429,
      "grad_norm": 12.236471176147461,
      "learning_rate": 0.00042857142857142855,
      "loss": 2.1926,
      "step": 41
    },
    {
      "epoch": 3.0,
      "grad_norm": 9.450023651123047,
      "learning_rate": 0.0004142857142857143,
      "loss": 2.1652,
      "step": 42
    },
    {
      "epoch": 3.0714285714285716,
      "grad_norm": 8.21554183959961,
      "learning_rate": 0.0004,
      "loss": 2.1658,
      "step": 43
    },
    {
      "epoch": 3.142857142857143,
      "grad_norm": 10.014697074890137,
      "learning_rate": 0.0003857142857142857,
      "loss": 2.0127,
      "step": 44
    },
    {
      "epoch": 3.2142857142857144,
      "grad_norm": 9.12767219543457,
      "learning_rate": 0.00037142857142857143,
      "loss": 2.0433,
      "step": 45
    },
    {
      "epoch": 3.2857142857142856,
      "grad_norm": 10.006830215454102,
      "learning_rate": 0.00035714285714285714,
      "loss": 2.0227,
      "step": 46
    },
    {
      "epoch": 3.357142857142857,
      "grad_norm": 10.233134269714355,
      "learning_rate": 0.00034285714285714285,
      "loss": 1.946,
      "step": 47
    },
    {
      "epoch": 3.4285714285714284,
      "grad_norm": 12.790680885314941,
      "learning_rate": 0.00032857142857142856,
      "loss": 1.8977,
      "step": 48
    },
    {
      "epoch": 3.5,
      "grad_norm": 7.687902450561523,
      "learning_rate": 0.00031428571428571427,
      "loss": 1.9865,
      "step": 49
    },
    {
      "epoch": 3.571428571428571,
      "grad_norm": 7.716342449188232,
      "learning_rate": 0.0003,
      "loss": 1.9736,
      "step": 50
    }
  ],
  "logging_steps": 1,
  "max_steps": 70,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 10,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
