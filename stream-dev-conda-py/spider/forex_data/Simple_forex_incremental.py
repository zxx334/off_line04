import requests
import time
import json
from datetime import datetime
import logging
import random
import os
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
from fake_useragent import UserAgent


class SimpleForexCrawler:
    def __init__(self, update_interval=3600):
        self.update_interval = update_interval
        self.last_update_time = {}
        self.setup_logging()
        self.setup_session()
        self.setup_storage()

        # è´§å¸å¯¹é…ç½®
        self.currency_pairs = [
            ('USD', 'EUR'), ('USD', 'GBP'), ('USD', 'JPY'), ('USD', 'CAD'),
            ('USD', 'AUD'), ('USD', 'CHF'), ('USD', 'CNY'), ('USD', 'HKD'),
            ('EUR', 'USD'), ('EUR', 'GBP'), ('EUR', 'JPY'), ('EUR', 'CHF'),
            ('GBP', 'USD'), ('GBP', 'EUR'), ('GBP', 'JPY'),
            ('JPY', 'USD'), ('JPY', 'EUR'), ('JPY', 'GBP')
        ]

    def setup_logging(self):
        """ç®€åŒ–æ—¥å¿—è®¾ç½®"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(message)s',
            handlers=[logging.StreamHandler()]
        )
        logging.info("ğŸ”„ å¤–æ±‡çˆ¬è™«å¯åŠ¨")

    def setup_session(self):
        """è®¾ç½®è¯·æ±‚ä¼šè¯"""
        self.session = requests.Session()
        retry_strategy = Retry(total=3, backoff_factor=1, status_forcelist=[429, 500, 502, 503, 504])
        adapter = HTTPAdapter(max_retries=retry_strategy)
        self.session.mount("http://", adapter)
        self.session.mount("https://", adapter)

    def setup_storage(self):
        """è®¾ç½®æ•°æ®å­˜å‚¨"""
        self.data_file = 'forex_data.json'
        logging.info(f"ğŸ“ æ•°æ®æ–‡ä»¶è·¯å¾„: {os.path.abspath(self.data_file)}")

        # ç¡®ä¿æ–‡ä»¶å­˜åœ¨ä¸”å¯å†™
        try:
            if not os.path.exists(self.data_file):
                with open(self.data_file, 'w', encoding='utf-8') as f:
                    json.dump([], f, ensure_ascii=False, indent=2)
                logging.info(f"âœ… åˆ›å»ºæ–°çš„æ•°æ®æ–‡ä»¶: {self.data_file}")
            else:
                with open(self.data_file, 'r', encoding='utf-8') as f:
                    existing_data = json.load(f)
                logging.info(f"âœ… åŠ è½½ç°æœ‰æ•°æ®æ–‡ä»¶ï¼Œå·²æœ‰ {len(existing_data)} æ¡è®°å½•")
        except Exception as e:
            logging.error(f"âŒ å­˜å‚¨è®¾ç½®å¤±è´¥: {e}")

    def needs_update(self, currency_pair):
        """æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°"""
        key = f"{currency_pair[0]}_{currency_pair[1]}"
        last_time = self.last_update_time.get(key)
        if not last_time:
            return True
        return (datetime.now() - last_time).total_seconds() >= self.update_interval

    def fetch_exchange_rate(self, base_currency, target_currency):
        """è·å–æ±‡ç‡æ•°æ®"""
        if not self.needs_update((base_currency, target_currency)):
            logging.info(f"â­ï¸ è·³è¿‡ {base_currency}/{target_currency}")
            return None

        url = f"https://api.frankfurter.app/latest?from={base_currency}&to={target_currency}"

        try:
            # éšæœºå»¶è¿Ÿ
            time.sleep(random.uniform(1, 3))

            headers = {
                'User-Agent': UserAgent().random,
                'Accept': 'application/json'
            }

            logging.info(f"ğŸŒ è¯·æ±‚ {base_currency}/{target_currency}")
            response = self.session.get(url, headers=headers, timeout=10)

            if response.status_code == 200:
                data = response.json()
                rate = data['rates'].get(target_currency)
                if rate:
                    logging.info(f"âœ… {base_currency}/{target_currency}: {rate}")
                    return {
                        'base_currency': base_currency,
                        'target_currency': target_currency,
                        'exchange_rate': rate,
                        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                        'date': datetime.now().strftime('%Y-%m-%d'),
                        'source': 'api'
                    }

            logging.warning(f"âš ï¸ APIè¯·æ±‚å¤±è´¥: {base_currency}/{target_currency} - HTTP {response.status_code}")

        except Exception as e:
            logging.error(f"âŒ è¯·æ±‚å¼‚å¸¸: {base_currency}/{target_currency} - {e}")

        return self.get_fallback_data(base_currency, target_currency)

    def get_fallback_data(self, base_currency, target_currency):
        """ç”Ÿæˆå¤‡ç”¨æ•°æ®"""
        fallback_rates = {
            ('USD', 'EUR'): 0.92, ('USD', 'GBP'): 0.79, ('USD', 'JPY'): 149.0,
            ('EUR', 'USD'): 1.09, ('EUR', 'GBP'): 0.86, ('EUR', 'JPY'): 161.0,
            ('GBP', 'USD'): 1.27, ('GBP', 'EUR'): 1.16, ('GBP', 'JPY'): 188.0,
            ('JPY', 'USD'): 0.0067, ('JPY', 'EUR'): 0.0062, ('JPY', 'GBP'): 0.0053
        }

        rate = fallback_rates.get((base_currency, target_currency),
                                  round(random.uniform(0.5, 2.0), 4))

        logging.info(f"ğŸ”„ ä½¿ç”¨å¤‡ç”¨æ•°æ®: {base_currency}/{target_currency}: {rate}")

        return {
            'base_currency': base_currency,
            'target_currency': target_currency,
            'exchange_rate': rate,
            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'date': datetime.now().strftime('%Y-%m-%d'),
            'source': 'fallback'
        }

    def save_data(self, new_data_list):
        """ä¿å­˜æ•°æ®åˆ°æ–‡ä»¶"""
        if not new_data_list:
            logging.warning("âš ï¸ æ²¡æœ‰æ•°æ®éœ€è¦ä¿å­˜")
            return False

        try:
            # è¯»å–ç°æœ‰æ•°æ®
            if os.path.exists(self.data_file):
                with open(self.data_file, 'r', encoding='utf-8') as f:
                    existing_data = json.load(f)
            else:
                existing_data = []

            # æ›´æ–°æˆ–æ·»åŠ æ•°æ®
            updated_count = 0
            new_count = 0

            for new_data in new_data_list:
                if not new_data:
                    continue

                key = f"{new_data['base_currency']}_{new_data['target_currency']}"

                # æŸ¥æ‰¾å¹¶æ›´æ–°ç°æœ‰è®°å½•
                found = False
                for i, item in enumerate(existing_data):
                    if item.get('base_currency') == new_data['base_currency'] and \
                            item.get('target_currency') == new_data['target_currency']:
                        existing_data[i] = new_data
                        found = True
                        updated_count += 1
                        break

                if not found:
                    existing_data.append(new_data)
                    new_count += 1

                self.last_update_time[key] = datetime.now()

            # ä¿å­˜å›æ–‡ä»¶
            with open(self.data_file, 'w', encoding='utf-8') as f:
                json.dump(existing_data, f, ensure_ascii=False, indent=2)

            logging.info(f"ğŸ’¾ æ•°æ®ä¿å­˜æˆåŠŸ: æ›´æ–°{updated_count}æ¡, æ–°å¢{new_count}æ¡, æ€»è®¡{len(existing_data)}æ¡è®°å½•")
            logging.info(f"ğŸ“ æ–‡ä»¶ä½ç½®: {os.path.abspath(self.data_file)}")
            return True

        except Exception as e:
            logging.error(f"âŒ ä¿å­˜æ•°æ®å¤±è´¥: {e}")
            return False

    def run_single_update(self):
        """æ‰§è¡Œå•æ¬¡æ›´æ–°"""
        logging.info(f"ğŸš€ å¼€å§‹æ›´æ–°æ±‡ç‡æ•°æ® - {datetime.now().strftime('%H:%M:%S')}")
        start_time = time.time()

        successful_pairs = 0
        data_to_save = []

        # éšæœºé¡ºåºå¤„ç†è´§å¸å¯¹
        random.shuffle(self.currency_pairs)

        for base, target in self.currency_pairs:
            data = self.fetch_exchange_rate(base, target)
            if data:
                data_to_save.append(data)
                successful_pairs += 1

        # ä¿å­˜æ‰€æœ‰æ•°æ®
        if data_to_save:
            save_success = self.save_data(data_to_save)
            if save_success:
                logging.info("âœ… æ•°æ®å·²æˆåŠŸå†™å…¥JSONæ–‡ä»¶")
            else:
                logging.error("âŒ æ•°æ®ä¿å­˜å¤±è´¥")
        else:
            logging.warning("âš ï¸ æ²¡æœ‰è·å–åˆ°ä»»ä½•æ•°æ®")

        total_time = time.time() - start_time
        logging.info(f"ğŸ“Š æ›´æ–°å®Œæˆ: æˆåŠŸ{successful_pairs}å¯¹, è€—æ—¶{total_time:.1f}ç§’")

        # æ˜¾ç¤ºç»Ÿè®¡
        self.show_stats()

    def show_stats(self):
        """æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯"""
        try:
            if os.path.exists(self.data_file):
                with open(self.data_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)

                total = len(data)
                api_data = sum(1 for item in data if item.get('source') == 'api')
                fallback_data = sum(1 for item in data if item.get('source') == 'fallback')

                logging.info(f"ğŸ“ˆ æ•°æ®ç»Ÿè®¡: æ€»è®°å½•{total}, APIæ•°æ®{api_data}, å¤‡ç”¨æ•°æ®{fallback_data}")

                # æ˜¾ç¤ºå‰å‡ æ¡æ•°æ®ä½œä¸ºç¤ºä¾‹
                if data:
                    logging.info("ğŸ“‹ æœ€æ–°æ•°æ®ç¤ºä¾‹:")
                    for i, item in enumerate(data[:3]):  # æ˜¾ç¤ºå‰3æ¡
                        logging.info(f"   {item['base_currency']}/{item['target_currency']}: {item['exchange_rate']} ({item['source']})")
            else:
                logging.warning("ğŸ“ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨")

        except Exception as e:
            logging.error(f"âŒ ç»Ÿè®¡æ˜¾ç¤ºå¤±è´¥: {e}")

    def run_continuous(self, hours=24):
        """æŒç»­è¿è¡Œæ¨¡å¼"""
        logging.info(f"ğŸ”„ æŒç»­è¿è¡Œæ¨¡å¼å¯åŠ¨ - {hours}å°æ—¶")
        end_time = time.time() + hours * 3600
        cycle = 0

        try:
            while time.time() < end_time:
                cycle += 1
                logging.info(f"\nğŸ”„ ç¬¬{cycle}è½®æ›´æ–°")

                self.run_single_update()

                if time.time() >= end_time:
                    break

                # ç­‰å¾…ä¸‹ä¸€è½®
                sleep_time = self.update_interval
                logging.info(f"â³ ç­‰å¾…{sleep_time}ç§’åç»§ç»­...")
                time.sleep(sleep_time)

            logging.info("ğŸ‰ æŒç»­è¿è¡Œå®Œæˆ")

        except KeyboardInterrupt:
            logging.info("â¹ï¸ ç”¨æˆ·ä¸­æ–­ï¼Œæ­£åœ¨ä¿å­˜æ•°æ®...")
            # ç¡®ä¿æ•°æ®ä¿å­˜
            if hasattr(self, 'data_to_save'):
                self.save_data(self.data_to_save)

    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        if hasattr(self, 'session'):
            self.session.close()
        logging.info("ğŸ”š çˆ¬è™«åœæ­¢")


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    crawler = SimpleForexCrawler(update_interval=10)  # 10ç§’æ›´æ–°ä¸€æ¬¡ç”¨äºæµ‹è¯•

    try:
        # å•æ¬¡è¿è¡Œæµ‹è¯•
        crawler.run_single_update()

        # æŒç»­è¿è¡Œï¼ˆå–æ¶ˆæ³¨é‡Šä½¿ç”¨ï¼‰
        # crawler.run_continuous(hours=24)

    except KeyboardInterrupt:
        logging.info("â¹ï¸ ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        logging.error(f"ğŸ’¥ è¿è¡Œé”™è¯¯: {e}")
    finally:
        crawler.cleanup()