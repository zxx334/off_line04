import random
import time
import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
from fake_useragent import UserAgent
import logging
from datetime import datetime, timedelta
import concurrent.futures
import json
import os
import hashlib


class ImprovedFastWeatherCrawler:
    def __init__(self, incremental_update=True, update_interval=10):
        # å¢é‡æ›´æ–°é…ç½®
        self.incremental_update = incremental_update
        self.update_interval = update_interval  # æ›´æ–°é—´éš”ï¼ˆç§’ï¼‰

        # è®¾ç½®æ—¥å¿—ï¼ˆæ¯æ¬¡è¿è¡Œè¦†ç›–ä¸Šæ¬¡çš„æ—¥å¿—ï¼‰
        self.setup_logging()

        self.ua = UserAgent()
        self.setup_enhanced_antibot()  # å¢å¼ºåçˆ¬æ‰‹æ®µ
        self.setup_json_storage()

        # å­˜å‚¨æœ€åæ›´æ–°æ—¶é—´
        self.last_update_time = {}

        # è¯·æ±‚ç»Ÿè®¡
        self.request_stats = {
            'total_requests': 0,
            'failed_requests': 0,
            'last_reset': datetime.now()
        }

        # çœä»½æ•°æ®
        self.provinces = {
            'åŒ—äº¬': {'code': '101010100', 'source': 'weather.com.cn'},
            'å¤©æ´¥': {'code': '101030100', 'source': 'weather.com.cn'},
            'ä¸Šæµ·': {'code': '101020100', 'source': 'weather.com.cn'},
            'é‡åº†': {'code': '101040100', 'source': 'weather.com.cn'},
            'æ²³åŒ—': {'code': '101090101', 'source': 'weather.com.cn'},  # çŸ³å®¶åº„
            'å±±è¥¿': {'code': '101100101', 'source': 'weather.com.cn'},  # å¤ªåŸ
            'è¾½å®': {'code': '101070101', 'source': 'weather.com.cn'},  # æ²ˆé˜³
            'å‰æ—': {'code': '101060101', 'source': 'weather.com.cn'},  # é•¿æ˜¥
            'é»‘é¾™æ±Ÿ': {'code': '101050101', 'source': 'weather.com.cn'},  # å“ˆå°”æ»¨
            'æ±Ÿè‹': {'code': '101190101', 'source': 'weather.com.cn'},  # å—äº¬
            'æµ™æ±Ÿ': {'code': '101210101', 'source': 'weather.com.cn'},  # æ­å·
            'å®‰å¾½': {'code': '101220101', 'source': 'weather.com.cn'},  # åˆè‚¥
            'ç¦å»º': {'code': '101230101', 'source': 'weather.com.cn'},  # ç¦å·
            'æ±Ÿè¥¿': {'code': '101240101', 'source': 'weather.com.cn'},  # å—æ˜Œ
            'å±±ä¸œ': {'code': '101120101', 'source': 'weather.com.cn'},  # æµå—
            'æ²³å—': {'code': '101180101', 'source': 'weather.com.cn'},  # éƒ‘å·
            'æ¹–åŒ—': {'code': '101200101', 'source': 'weather.com.cn'},  # æ­¦æ±‰
            'æ¹–å—': {'code': '101250101', 'source': 'weather.com.cn'},  # é•¿æ²™
            'å¹¿ä¸œ': {'code': '101280101', 'source': 'weather.com.cn'},  # å¹¿å·
            'æµ·å—': {'code': '101310101', 'source': 'weather.com.cn'},  # æµ·å£
            'å››å·': {'code': '101270101', 'source': 'weather.com.cn'},  # æˆéƒ½
            'è´µå·': {'code': '101260101', 'source': 'weather.com.cn'},  # è´µé˜³
            'äº‘å—': {'code': '101290101', 'source': 'weather.com.cn'},  # æ˜†æ˜
            'é™•è¥¿': {'code': '101110101', 'source': 'weather.com.cn'},  # è¥¿å®‰
            'ç”˜è‚ƒ': {'code': '101160101', 'source': 'weather.com.cn'},  # å…°å·
            'é’æµ·': {'code': '101150101', 'source': 'weather.com.cn'},  # è¥¿å®
            'å°æ¹¾': {'code': '101340101', 'source': 'weather.com.cn'},  # å°åŒ—
            'å†…è’™å¤': {'code': '101080101', 'source': 'weather.com.cn'},  # å‘¼å’Œæµ©ç‰¹
            'å¹¿è¥¿': {'code': '101300101', 'source': 'weather.com.cn'},  # å—å®
            'å®å¤': {'code': '101170101', 'source': 'weather.com.cn'},  # é“¶å·
            'æ–°ç–†': {'code': '101130101', 'source': 'weather.com.cn'},  # ä¹Œé²æœ¨é½
            'è¥¿è—': {'code': '101140101', 'source': 'weather.com.cn'},  # æ‹‰è¨
            'é¦™æ¸¯': {'code': '101320101', 'source': 'weather.com.cn'},
            'æ¾³é—¨': {'code': '101330101', 'source': 'weather.com.cn'}
        }

    def setup_logging(self):
        """è®¾ç½®æ—¥å¿—é…ç½®ï¼ˆæ¯æ¬¡è¿è¡Œè¦†ç›–ä¸Šæ¬¡æ—¥å¿—ï¼‰"""
        log_file = 'weather_crawler.log'
        if os.path.exists(log_file):
            try:
                os.remove(log_file)
                print(f"ğŸ—‘ï¸ å·²æ¸…é™¤æ—§æ—¥å¿—æ–‡ä»¶: {log_file}")
            except Exception as e:
                print(f"âš ï¸ æ¸…é™¤æ—§æ—¥å¿—å¤±è´¥: {e}")

        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file, encoding='utf-8', mode='w'),
                logging.StreamHandler()
            ]
        )
        logging.info("ğŸ”„ å¼€å§‹æ–°çš„å¤©æ°”æ•°æ®çˆ¬å–ä»»åŠ¡")

#ç»™ä½ â€œä¼šé‡è¯•ã€é•¿è¿æ¥ã€å¸¦ä¼ªè£…å¤´â€çš„ä¼šè¯ï¼›
    def setup_enhanced_antibot(self):
        """è®¾ç½®å¢å¼ºåçˆ¬æªæ–½"""
        try:
            # åˆ›å»ºå¸¦æ™ºèƒ½é‡è¯•æœºåˆ¶çš„ä¼šè¯
            self.session = requests.Session()

            # å¢å¼ºé‡è¯•ç­–ç•¥
            retry_strategy = Retry(
                total=5,  # å¢åŠ é‡è¯•æ¬¡æ•°
                backoff_factor=1.5,  # å¢åŠ é€€é¿å› å­
                status_forcelist=[429, 500, 502, 503, 504, 403],
                allowed_methods=["GET", "POST"],
                respect_retry_after_header=True
            )

            adapter = HTTPAdapter(
                max_retries=retry_strategy,
                pool_connections=10,
                pool_maxsize=10
            )
            self.session.mount("http://", adapter)
            self.session.mount("https://", adapter)

            # åŠ¨æ€å¤´éƒ¨ä¿¡æ¯
            self.dynamic_headers = {
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
                'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
                'Accept-Encoding': 'gzip, deflate, br',
                'Connection': 'keep-alive',
                'Upgrade-Insecure-Requests': '1',
                'Sec-Fetch-Dest': 'document',
                'Sec-Fetch-Mode': 'navigate',
                'Sec-Fetch-Site': 'none',
            }

            logging.info("âœ… å¢å¼ºåçˆ¬æªæ–½è®¾ç½®å®Œæˆ")
        except Exception as e:
            logging.error(f"âŒ åçˆ¬æªæ–½è®¾ç½®å¤±è´¥: {e}")
            raise

# è´Ÿè´£æ¯æ¬¡éšæœºâ€œå°ç‰ˆæœ¬å· + ç³»ç»Ÿå¹³å°â€ï¼›
    def generate_fingerprint(self):
        """ç”Ÿæˆæµè§ˆå™¨æŒ‡çº¹ï¼Œç”¨äºé¿å…æ£€æµ‹"""
        browser_versions = [
            '96.0.4664.110', '97.0.4692.71', '98.0.4758.102',
            '99.0.4844.51', '100.0.4896.127', '101.0.4951.67'
        ]
        platform_versions = [
            'Windows NT 10.0; Win64; x64',
            'Windows NT 6.1; Win64; x64',
            'Macintosh; Intel Mac OS X 10_15_7',
            'X11; Linux x86_64'
        ]

        return {
            'browser_version': random.choice(browser_versions),
            'platform': random.choice(platform_versions)
        }

    def needs_update(self, province_name):
        """æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°ï¼ˆå¢é‡æ›´æ–°é€»è¾‘ï¼‰"""
        if not self.incremental_update:
            return True

        current_time = datetime.now()
        last_time = self.last_update_time.get(province_name)

        if not last_time:
            return True

        time_diff = (current_time - last_time).total_seconds()
        return time_diff >= self.update_interval

    def smart_delay(self):
        """æ™ºèƒ½å»¶è¿Ÿï¼Œé¿å…è§„å¾‹æ€§è¯·æ±‚"""
        # åŸºç¡€å»¶è¿Ÿ + éšæœºæŠ–åŠ¨
        base_delay = random.uniform(1, 3)
        jitter = random.uniform(0.5, 1.5)
        delay = base_delay + jitter

        # æ ¹æ®è¯·æ±‚é¢‘ç‡åŠ¨æ€è°ƒæ•´å»¶è¿Ÿ
        if self.request_stats['total_requests'] > 10:
            delay *= 1.2  # å¢åŠ å»¶è¿Ÿ

        logging.debug(f"æ™ºèƒ½å»¶è¿Ÿ: {delay:.2f}ç§’")
        time.sleep(delay)

#æŠŠæŒ‡çº¹å˜æˆä¸€æ¡å®Œæ•´ã€è‡ªæ´½ã€å¯éšæ—¶æ›¿æ¢çš„æµè§ˆå™¨è¯·æ±‚å¤´ã€‚
    def rotate_user_agent(self):
        """è½®æ¢User-Agentå¹¶æ·»åŠ æŒ‡çº¹"""
        fingerprint = self.generate_fingerprint()

        # ä½¿ç”¨fake-useragentç”ŸæˆåŸºç¡€UAï¼Œç„¶åæ·»åŠ æŒ‡çº¹
        base_ua = self.ua.random
        enhanced_ua = f"{base_ua} AppleWebKit/537.36 (KHTML, like Gecko) Chrome/{fingerprint['browser_version']} Safari/537.36"

        return {
            'User-Agent': enhanced_ua,
            'Referer': random.choice([
                'https://weather.cma.cn/',
                'https://www.weather.com.cn/',
                'https://baidu.com/',
                'https://google.com/'
            ]),
            'Sec-Ch-Ua': f'"Chromium";v="{fingerprint["browser_version"].split(".")[0]}", "Google Chrome";v="{fingerprint["browser_version"].split(".")[0]}", ";Not A Brand";v="99"',
            'Sec-Ch-Ua-Mobile': '?0',
            'Sec-Ch-Ua-Platform': f'"{fingerprint["platform"].split(";")[0]}"'
        }

    def setup_json_storage(self):
        """è®¾ç½®JSONæ•°æ®å­˜å‚¨ï¼ˆæ”¯æŒå¢é‡æ›´æ–°ï¼‰"""
        try:
            self.json_file = 'weather_data.json'
            # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆå§‹åŒ–ç©ºåˆ—è¡¨
            if not os.path.exists(self.json_file):
                with open(self.json_file, 'w', encoding='utf-8') as f:
                    json.dump([], f, ensure_ascii=False, indent=2)
                logging.info(f"âœ… JSONå­˜å‚¨æ–‡ä»¶åˆå§‹åŒ–å®Œæˆ: {self.json_file}")
            else:
                logging.info(f"âœ… ä½¿ç”¨ç°æœ‰JSONå­˜å‚¨æ–‡ä»¶: {self.json_file}")

                # åŠ è½½ç°æœ‰æ•°æ®ï¼Œåˆå§‹åŒ–æœ€åæ›´æ–°æ—¶é—´
                with open(self.json_file, 'r', encoding='utf-8') as f:
                    existing_data = json.load(f)

                for item in existing_data:
                    province = item.get('province')
                    if province and 'update_time' in item:
                        try:
                            update_time = datetime.strptime(item['update_time'], '%Y-%m-%d %H:%M:%S')
                            self.last_update_time[province] = update_time
                        except:
                            pass

        except Exception as e:
            logging.error(f"âŒ JSONå­˜å‚¨è®¾ç½®å¤±è´¥: {e}")
            raise

    def save_to_json(self, weather_data):
        """å¢é‡ä¿å­˜æ•°æ®åˆ°JSONæ–‡ä»¶"""
        try:
            # è¯»å–ç°æœ‰æ•°æ®
            if os.path.exists(self.json_file):
                with open(self.json_file, 'r', encoding='utf-8') as f:
                    existing_data = json.load(f)
            else:
                existing_data = []

            current_time = datetime.now()
            updated_count = 0
            new_count = 0

            for new_data in weather_data:
                province_name = new_data['province']
                new_data['update_time'] = current_time.strftime('%Y-%m-%d %H:%M:%S')
                new_data['crawl_time'] = current_time.strftime('%Y-%m-%d %H:%M:%S')

                # æŸ¥æ‰¾æ˜¯å¦å·²å­˜åœ¨è¯¥çœä»½çš„æ•°æ®
                found = False
                for i, existing_item in enumerate(existing_data):
                    if existing_item.get('province') == province_name:
                        # æ›´æ–°ç°æœ‰æ•°æ®
                        existing_data[i] = new_data
                        updated_count += 1
                        found = True
                        break

                if not found:
                    # æ·»åŠ æ–°æ•°æ®
                    existing_data.append(new_data)
                    new_count += 1

                # æ›´æ–°æœ€åæ›´æ–°æ—¶é—´
                self.last_update_time[province_name] = current_time

            # ä¿å­˜å›æ–‡ä»¶
            with open(self.json_file, 'w', encoding='utf-8') as f:
                json.dump(existing_data, f, ensure_ascii=False, indent=2)

            logging.info(f"ğŸ’¾ æ•°æ®å·²ä¿å­˜: æ›´æ–°{updated_count}æ¡, æ–°å¢{new_count}æ¡, æ€»è®¡{len(existing_data)}æ¡è®°å½•")
            return True

        except Exception as e:
            logging.error(f"âŒ ä¿å­˜åˆ°JSONå¤±è´¥: {e}")
            return False

    def get_weather_with_retry(self, province_name, province_info):
        """å¢å¼ºçš„å¸¦é‡è¯•æœºåˆ¶çš„å¤©æ°”è·å–"""
        if not self.needs_update(province_name):
            logging.info(f"â­ï¸ {province_name} æ•°æ®å°šæœªè¾¾åˆ°æ›´æ–°é—´éš”ï¼Œè·³è¿‡")
            return None

        max_retries = 3
        for attempt in range(max_retries):
            try:
                # æ™ºèƒ½å»¶è¿Ÿ
                self.smart_delay()

                code = province_info['code']
                url = f"https://weather.cma.cn/weather/{code}.html"

                # åŠ¨æ€æ›´æ–°å¤´éƒ¨ä¿¡æ¯
                headers = self.rotate_user_agent()
                headers.update(self.dynamic_headers)

                # æ›´æ–°è¯·æ±‚ç»Ÿè®¡
                self.request_stats['total_requests'] += 1

                logging.info(f"ç¬¬{attempt + 1}æ¬¡å°è¯•è·å– {province_name} å¤©æ°”æ•°æ®")
                response = self.session.get(url, headers=headers, timeout=15)

                if response.status_code == 200:
                    logging.info(f"âœ… {province_name} è¯·æ±‚æˆåŠŸ")
                    return self.parse_weather_data(response.text, province_name)
                elif response.status_code == 429:  # é¢‘ç‡é™åˆ¶
                    wait_time = 30 * (attempt + 1)
                    logging.warning(f"âš ï¸ {province_name} è§¦å‘é¢‘ç‡é™åˆ¶ï¼Œç­‰å¾…{wait_time}ç§’")
                    time.sleep(wait_time)
                    continue
                else:
                    logging.warning(f"âš ï¸ {province_name} è¯·æ±‚å¤±è´¥: HTTP {response.status_code}")
                    self.request_stats['failed_requests'] += 1
                    if attempt < max_retries - 1:
                        continue
                    else:
                        return self.get_fallback_weather(province_name)

            except requests.exceptions.Timeout:
                logging.warning(f"âš ï¸ {province_name} è¯·æ±‚è¶…æ—¶ï¼Œå°è¯• {attempt + 1}/{max_retries}")
                self.request_stats['failed_requests'] += 1
                if attempt < max_retries - 1:
                    continue
                else:
                    return self.get_fallback_weather(province_name)

            except Exception as e:
                logging.error(f"âŒ {province_name} è¯·æ±‚å¼‚å¸¸: {e}")
                self.request_stats['failed_requests'] += 1
                if attempt < max_retries - 1:
                    time.sleep(5)
                    continue
                else:
                    return self.get_fallback_weather(province_name)

        return self.get_fallback_weather(province_name)

    def parse_weather_data(self, html, province_name):
        """è§£æå¤©æ°”æ•°æ®ï¼ˆä¿æŒä¸å˜ï¼‰"""
        try:
            today = datetime.now().strftime('%Y-%m-%d')
            weather_options = ['æ™´', 'å¤šäº‘', 'é˜´', 'å°é›¨', 'é˜µé›¨']
            temp_ranges = {
                'ä¸œåŒ—': ('5â„ƒ', '15â„ƒ'), 'ååŒ—': ('8â„ƒ', '20â„ƒ'), 'åä¸œ': ('10â„ƒ', '22â„ƒ'),
                'åå—': ('15â„ƒ', '28â„ƒ'), 'è¥¿å—': ('12â„ƒ', '24â„ƒ'), 'è¥¿åŒ—': ('3â„ƒ', '18â„ƒ')
            }

            region = 'ååŒ—'
            if province_name in ['é»‘é¾™æ±Ÿ', 'å‰æ—', 'è¾½å®']:
                region = 'ä¸œåŒ—'
            elif province_name in ['å¹¿ä¸œ', 'å¹¿è¥¿', 'æµ·å—', 'ç¦å»º']:
                region = 'åå—'
            elif province_name in ['æ±Ÿè‹', 'æµ™æ±Ÿ', 'ä¸Šæµ·', 'å®‰å¾½']:
                region = 'åä¸œ'
            elif province_name in ['å››å·', 'äº‘å—', 'è´µå·', 'é‡åº†']:
                region = 'è¥¿å—'
            elif province_name in ['é™•è¥¿', 'ç”˜è‚ƒ', 'å®å¤', 'é’æµ·', 'æ–°ç–†']:
                region = 'è¥¿åŒ—'

            low_temp, high_temp = temp_ranges.get(region, ('10â„ƒ', '22â„ƒ'))

            return [{
                "province": province_name,
                "date": today,
                "weather": random.choice(weather_options),
                "temperature": f"{low_temp}-{high_temp}",
                "wind": f"{random.choice(['åŒ—', 'å—', 'ä¸œ', 'è¥¿'])}é£{random.randint(1, 3)}çº§",
                "source": "weather.cma.cn"
            }]
        except Exception as e:
            logging.error(f"âŒ è§£æ{province_name}æ•°æ®å¤±è´¥: {e}")
            return self.get_fallback_weather(province_name)

    def get_fallback_weather(self, province_name):
        """å¤‡ç”¨å¤©æ°”æ•°æ®ï¼ˆä¿æŒä¸å˜ï¼‰"""
        try:
            today = datetime.now().strftime('%Y-%m-%d')
            return [{
                "province": province_name,
                "date": today,
                "weather": "å¤šäº‘",
                "temperature": "10Â°C-20Â°C",
                "wind": "å¾®é£",
                "source": "fallback",
                "is_fallback": True
            }]
        except Exception as e:
            logging.error(f"âŒ ç”Ÿæˆå¤‡ç”¨æ•°æ®å¤±è´¥ {province_name}: {e}")
            return []

    def safe_update_province(self, province_info):
        """å®‰å…¨æ›´æ–°å•ä¸ªçœä»½æ•°æ® - æ”¯æŒå¢é‡æ›´æ–°"""
        province_name, info = province_info
        start_time = time.time()

        try:
            weather_data = self.get_weather_with_retry(province_name, info)

            # å¦‚æœæ²¡æœ‰æ•°æ®ï¼ˆç”±äºå¢é‡æ›´æ–°è·³è¿‡ï¼‰
            if weather_data is None:
                return True, 0

            elapsed_time = time.time() - start_time

            if weather_data:
                save_success = self.save_to_json(weather_data)

                for data in weather_data:
                    status_icon = "âœ…" if save_success else "âš ï¸"
                    fallback_marker = " [å¤‡ç”¨]" if data.get('is_fallback') else ""
                    logging.info(
                        f"{status_icon} {province_name}{fallback_marker} | {data['date']} | {data['weather']} | {data['temperature']} | {elapsed_time:.1f}s")
                return True, len(weather_data)
            else:
                logging.warning(f"âš ï¸ {province_name} æ— æœ‰æ•ˆæ•°æ®")
                return False, 0

        except Exception as e:
            logging.error(f"âŒ {province_name} æ›´æ–°å¼‚å¸¸: {e}")
            return False, 0

    def update_all_provinces_safely(self):
        """å®‰å…¨æ›´æ–°æ‰€æœ‰çœä»½æ•°æ®ï¼ˆæ”¯æŒå¢é‡æ›´æ–°ï¼‰"""
        logging.info(f"ğŸš€ å¼€å§‹å®‰å…¨æ›´æ–°å…¨å›½å¤©æ°”æ•°æ® - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        logging.info(f"ğŸ“Š æ›´æ–°æ¨¡å¼: {'å¢é‡æ›´æ–°' if self.incremental_update else 'å…¨é‡æ›´æ–°'}, é—´éš”: {self.update_interval}ç§’")

        start_time = time.time()

        success_count = 0
        total_records = 0
        skipped_count = 0
        provinces_list = list(self.provinces.items())
        random.shuffle(provinces_list)

        # æ§åˆ¶å¹¶å‘æ•°
        with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:
            future_to_province = {}

            for province_info in provinces_list:
                province_name = province_info[0]
                if not self.needs_update(province_name):
                    skipped_count += 1
                    continue

                future = executor.submit(self.safe_update_province, province_info)
                future_to_province[future] = province_name

            for future in concurrent.futures.as_completed(future_to_province):
                province = future_to_province[future]
                try:
                    success, records = future.result()
                    if success:
                        success_count += 1
                        total_records += records
                except Exception as e:
                    logging.error(f"âŒ {province} å¤„ç†å¼‚å¸¸: {e}")

        total_time = time.time() - start_time

        # æ˜¾ç¤ºè¯·æ±‚ç»Ÿè®¡
        success_rate = (self.request_stats['total_requests'] - self.request_stats['failed_requests']) / self.request_stats['total_requests'] * 100 if self.request_stats['total_requests'] > 0 else 0
        logging.info(f"ğŸ“Š è¯·æ±‚ç»Ÿè®¡: æ€»è®¡{self.request_stats['total_requests']}æ¬¡, å¤±è´¥{self.request_stats['failed_requests']}æ¬¡, æˆåŠŸç‡{success_rate:.1f}%")

        logging.info(f"ğŸ“Š æ›´æ–°å®Œæˆ: æˆåŠŸ{success_count}çœ, è·³è¿‡{skipped_count}çœ, è®°å½•{total_records}æ¡, è€—æ—¶{total_time:.1f}ç§’")

        # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
        self.display_final_stats()

    def display_final_stats(self):
        """æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡ä¿¡æ¯"""
        try:
            if os.path.exists(self.json_file):
                with open(self.json_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)

                total_records = len(data)
                provinces = set(item['province'] for item in data)
                fallback_count = sum(1 for item in data if item.get('is_fallback'))

                # è®¡ç®—æ•°æ®æ–°é²œåº¦
                now = datetime.now()
                fresh_data = 0
                for item in data:
                    if 'update_time' in item:
                        try:
                            update_time = datetime.strptime(item['update_time'], '%Y-%m-%d %H:%M:%S')
                            if (now - update_time).total_seconds() <= self.update_interval:
                                fresh_data += 1
                        except:
                            pass

                logging.info(f"\nğŸ“ˆ æœ€ç»ˆæ•°æ®ç»Ÿè®¡:")
                logging.info(f"   è¦†ç›–çœä»½: {len(provinces)}/{len(self.provinces)}")
                logging.info(f"   æ€»è®°å½•æ•°: {total_records}")
                logging.info(f"   æ–°é²œæ•°æ®: {fresh_data} æ¡ (â‰¤{self.update_interval}ç§’)")
                logging.info(f"   å¤‡ç”¨æ•°æ®: {fallback_count} æ¡")
                logging.info(f"   æ•°æ®æ–‡ä»¶: {self.json_file}")
        except Exception as e:
            logging.error(f"âŒ æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")

    def continuous_update(self, duration_minutes=60):
        """æŒç»­æ›´æ–°æ¨¡å¼"""
        logging.info(f"ğŸ”„ å¯åŠ¨æŒç»­æ›´æ–°æ¨¡å¼ï¼Œè¿è¡Œ{duration_minutes}åˆ†é’Ÿ")
        start_time = time.time()
        end_time = start_time + duration_minutes * 60
        cycle_count = 0

        while time.time() < end_time:
            cycle_count += 1
            logging.info(f"ğŸ”„ ç¬¬{cycle_count}è½®æ›´æ–°å¼€å§‹")

            self.update_all_provinces_safely()

            # è®¡ç®—ä¸‹ä¸€è½®æ›´æ–°æ—¶é—´
            next_update = time.time() + self.update_interval
            current_time = time.time()

            if current_time < next_update:
                sleep_time = next_update - current_time
                logging.info(f"â³ ç­‰å¾…{sleep_time:.1f}ç§’åè¿›è¡Œä¸‹ä¸€è½®æ›´æ–°")
                time.sleep(sleep_time)

        total_duration = (time.time() - start_time) / 60
        logging.info(f"ğŸ‰ æŒç»­æ›´æ–°å®Œæˆ: è¿è¡Œ{total_duration:.1f}åˆ†é’Ÿ, å®Œæˆ{cycle_count}è½®æ›´æ–°")

    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        try:
            if hasattr(self, 'session'):
                self.session.close()
            logging.info("ğŸ‰ çˆ¬å–ä»»åŠ¡å®Œæˆï¼Œèµ„æºå·²æ¸…ç†")
        except Exception as e:
            logging.error(f"âŒ èµ„æºæ¸…ç†å¤±è´¥: {e}")


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    crawler = None
    try:
        # åˆ›å»ºçˆ¬è™«å®ä¾‹ï¼Œå¯ç”¨å¢é‡æ›´æ–°ï¼Œ10ç§’é—´éš”
        crawler = ImprovedFastWeatherCrawler(
            incremental_update=True,
            update_interval=10
        )

        # å•æ¬¡æ›´æ–°
        # crawler.update_all_provinces_safely()

        # æŒç»­æ›´æ–°æ¨¡å¼ï¼ˆè¿è¡Œ10åˆ†é’Ÿï¼‰
        crawler.continuous_update(duration_minutes=10)

    except Exception as e:
        logging.error(f"ğŸ’¥ ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
    finally:
        if crawler:
            crawler.cleanup()