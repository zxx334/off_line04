### Flink CDC æ•°æ®åŒæ­¥é¡¹ç›®æ–‡æ¡£
#### ğŸ“‹ é¡¹ç›®æ¦‚è¿°
æœ¬é¡¹ç›®å®ç°ä» PostgreSQL å’Œ SQLServer æ•°æ®åº“é€šè¿‡ Flink CDC å®æ—¶åŒæ­¥æ•°æ®åˆ° Kafkaï¼Œå¹¶ä½¿ç”¨ Doris Routine Load æ–¹å¼åŠ è½½åˆ° Doris æ•°æ®ä»“åº“ï¼Œé‡‡ç”¨åŠ¨æ€åˆ†åŒºå’Œåˆ†æ¡¶ä¼˜åŒ–ã€‚


ğŸ—ï¸ ç³»ç»Ÿæ¶æ„

    PostgreSQL/SQLServer â†’ Flink CDC â†’ Kafka â†’ Doris Routine Load â†’ Doris


ğŸ“ é¡¹ç›®ç»“æ„

    stream-realtimeTT2/
    â”œâ”€â”€ src/
    â”‚   â””â”€â”€ main/
    â”‚       â””â”€â”€ java/
    â”‚           â””â”€â”€ com/
    â”‚               â””â”€â”€ zxx/
    â”‚                   â”œâ”€â”€ CDC_PG_Server_Kafka_doris.java
    â”‚                   â””â”€â”€ MultiSourceCDCToKafka.java
    â”œâ”€â”€ pom.xml
    â””â”€â”€ README.md



âš™ï¸ ç¯å¢ƒé…ç½®
1. PostgreSQL é…ç½®


ä½ç½®: CDC_PG_Server_Kafka_doris.java ç¬¬ 47-49 è¡Œ

    private final String url = "jdbc:postgresql://cdh03:5432/test_db";
    private final String user = "postgres";
    private final String password = "123456";


é—®é¢˜: éœ€è¦åˆ›å»ºå˜æ›´æ—¥å¿—è¡¨å’Œè§¦å‘å™¨


è§£å†³æ–¹æ¡ˆ:


    -- åˆ›å»ºå˜æ›´æ—¥å¿—è¡¨
    CREATE TABLE users_changelog (
    change_id BIGSERIAL PRIMARY KEY,
    table_name VARCHAR(50),
    record_id INTEGER,
    operation VARCHAR(10),
    old_data JSON,
    new_data JSON,
    change_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP
    );
    
    -- åˆ›å»ºè§¦å‘å™¨å‡½æ•°
    CREATE OR REPLACE FUNCTION users_change_trigger()
    RETURNS TRIGGER AS $$
    BEGIN
    IF TG_OP = 'INSERT' THEN
    INSERT INTO users_changelog (table_name, record_id, operation, new_data)
    VALUES ('users', NEW.id, 'I', row_to_json(NEW));
    RETURN NEW;
    ELSIF TG_OP = 'UPDATE' THEN
    INSERT INTO users_changelog (table_name, record_id, operation, old_data, new_data)
    VALUES ('users', NEW.id, 'U', row_to_json(OLD), row_to_json(NEW));
    RETURN NEW;
    ELSIF TG_OP = 'DELETE' THEN
    INSERT INTO users_changelog (table_name, record_id, operation, old_data)
    VALUES ('users', OLD.id, 'D', row_to_json(OLD));
    RETURN OLD;
    END IF;
    RETURN NULL;
    END;
    $$ LANGUAGE plpgsql;
    
    -- åˆ›å»ºè§¦å‘å™¨
    CREATE TRIGGER users_cdc_trigger
    AFTER INSERT OR UPDATE OR DELETE ON users
    FOR EACH ROW EXECUTE FUNCTION users_change_trigger();


2. Kafka é…ç½®

ä½ç½®: CDC_PG_Server_Kafka_doris.java ç¬¬ 24-28 è¡Œ

    observedStream.addSink(new FlinkKafkaProducer<>(
    "cdh03:9092",
    "cdc-data-topic",
    new SimpleStringSchema()
    )).name("kafka-sink");


3. Doris é…ç½®

3.1 Doris è¿æ¥é—®é¢˜

é—®é¢˜: é»˜è®¤ç«¯å£è¿æ¥å¤±è´¥

é”™è¯¯ä¿¡æ¯:

    mysql -h cdh03 -P 9030 -u root
    ERROR 2003 (HY000): Can't connect to MySQL server on 'cdh03' (111)


è§£å†³æ–¹æ¡ˆ: ä½¿ç”¨ä¿®æ”¹åçš„ç«¯å£


    # æ£€æŸ¥å®é™…ç›‘å¬ç«¯å£
    netstat -tlnp | grep doris
    
    # ä½¿ç”¨æ­£ç¡®ç«¯å£è¿æ¥
    mysql -h cdh03 -P 19030 -u root

3.2 Doris è¡¨åˆ›å»ºé—®é¢˜

é—®é¢˜: DUPLICATE KEY åˆ—é¡ºåºé”™è¯¯

é”™è¯¯ä¿¡æ¯:


    ERROR 1105 (HY000): errCode = 2, detailMessage = Key columns should be a ordered prefix of the schema.


è§£å†³æ–¹æ¡ˆ: è°ƒæ•´åˆ—é¡ºåºï¼Œå°†åˆ†åŒºé”®æ”¾åœ¨å‰é¢

    CREATE TABLE IF NOT EXISTS pg_users_doris (
    `id` BIGINT,
    `cdc_time` DATETIME DEFAULT CURRENT_TIMESTAMP,  -- åˆ†åŒºé”®æ”¾åœ¨å‰é¢
    `name` VARCHAR(50),
    `email` VARCHAR(100),
    `created_at` DATETIME,
    `updated_at` DATETIME,
    `source_db` VARCHAR(20) DEFAULT 'postgresql'
    ) ENGINE=OLAP
    DUPLICATE KEY(`id`, `cdc_time`)  -- ä¸è¡¨å®šä¹‰é¡ºåºä¸€è‡´
    PARTITION BY RANGE (`cdc_time`)()
    DISTRIBUTED BY HASH(`id`) BUCKETS 8
    PROPERTIES (
    "dynamic_partition.enable" = "true",
    "dynamic_partition.time_unit" = "DAY",
    "dynamic_partition.start" = "-7",
    "dynamic_partition.end" = "3",
    "dynamic_partition.prefix" = "p",
    "dynamic_partition.buckets" = "8",
    "replication_num" = "1"
    );


3.3 Routine Load é…ç½®é—®é¢˜

é—®é¢˜: max_batch_rows å‚æ•°å€¼å¤ªå°

é”™è¯¯ä¿¡æ¯:

    ERROR 1105 (HY000): errCode = 2, detailMessage = max_batch_rows should > 200000

è§£å†³æ–¹æ¡ˆ: è°ƒæ•´å‚æ•°å€¼


    CREATE ROUTINE LOAD cdc_db.pg_users_load ON pg_users_doris
    PROPERTIES
    (
    "desired_concurrent_number" = "3",
    "max_batch_interval" = "20",
    "max_batch_rows" = "200000",  -- ä¿®æ”¹ä¸º >= 200000
    "max_batch_size" = "104857600",
    "strict_mode" = "false",
    "format" = "json"
    )
    FROM KAFKA
    (
    "kafka_broker_list" = "cdh03:9092",
    "kafka_topic" = "cdc-data-topic",
    "property.group.id" = "doris_pg_users"
    );


ğŸ”§ Maven ä¾èµ–é…ç½®

ä¸»è¦ä¾èµ– (pom.xml)

    <!-- Flink CDC è¿æ¥å™¨ -->
    <dependency>
        <groupId>com.ververica</groupId>
        <artifactId>flink-connector-postgres-cdc</artifactId>
        <version>2.4.2</version>
    </dependency>
    
    <!-- SQLServer CDC è¿æ¥å™¨ -->
    <dependency>
        <groupId>com.ververica</groupId>
        <artifactId>flink-connector-sqlserver-cdc</artifactId>
        <version>2.4.2</version>
    </dependency>
    
    <!-- Flink æ ¸å¿ƒ -->
    <dependency>
        <groupId>org.apache.flink</groupId>
        <artifactId>flink-streaming-java_2.12</artifactId>
        <version>1.14.6</version>
    </dependency>
    
    <!-- Kafka è¿æ¥å™¨ -->
    <dependency>
        <groupId>org.apache.flink</groupId>
        <artifactId>flink-connector-kafka_2.12</artifactId>
        <version>1.14.6</version>
    </dependency>


###  è¿è¡Œæ­¥éª¤

1. å¯åŠ¨ Flink ä½œä¸š ï¼ˆcdh01ï¼‰é‡Œé¢


2. éªŒè¯æ•°æ®æµæ°´çº¿

cdh03è¿›å…¥doris é‡ŒæŸ¥çœ‹

        -- æ£€æŸ¥ Routine Load çŠ¶æ€
        SHOW ROUTINE LOAD;
        
        -- æ£€æŸ¥æ•°æ®æ˜¯å¦åŠ è½½
        SELECT * FROM pg_users_doris LIMIT 10;
        SELECT COUNT(*) FROM pg_users_doris;


3. ç›‘æ§æ•°æ®æµ

Flink æ§åˆ¶å°: æŸ¥çœ‹ CDC æ•°æ®æ•è·æ—¥å¿—

Kafka: ç›‘æ§ cdc-data-topic ä¸»é¢˜æ¶ˆæ¯

Doris: æ£€æŸ¥è¡¨æ•°æ®å’Œ Routine Load çŠ¶æ€



ğŸ› å¸¸è§é—®é¢˜æ’æŸ¥


### é—®é¢˜1: Flink CDC æ— æ•°æ®è¾“å‡º

æ£€æŸ¥é¡¹:

PostgreSQL è§¦å‘å™¨æ˜¯å¦åˆ›å»ºæˆåŠŸ

users_changelog è¡¨æ˜¯å¦æœ‰æ•°æ®

æ•°æ®åº“è¿æ¥é…ç½®æ˜¯å¦æ­£ç¡®

### é—®é¢˜2: Kafka æ— æ¶ˆæ¯
æ£€æŸ¥é¡¹:

Kafka æœåŠ¡æ˜¯å¦è¿è¡Œ

ä¸»é¢˜æ˜¯å¦å­˜åœ¨

Flink Kafka Producer é…ç½®



### é—®é¢˜3: Doris è¡¨æ— æ•°æ®
æ£€æŸ¥é¡¹:

Routine Load çŠ¶æ€æ˜¯å¦ä¸º RUNNING

æ•°æ®æ ¼å¼æ˜¯å¦åŒ¹é…

Kafka åç§»é‡æ˜¯å¦æ­£ç¡®



### é—®é¢˜4: å†…å­˜ä¸è¶³é”™è¯¯

é”™è¯¯ä¿¡æ¯: Process memory not enough

è§£å†³æ–¹æ¡ˆ: å¢åŠ  Doris BE å†…å­˜é…ç½®æˆ–ä¼˜åŒ–æŸ¥è¯¢

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–


1. åŠ¨æ€åˆ†åŒºé…ç½®
   æŒ‰å¤©è‡ªåŠ¨åˆ†åŒº

ä¿ç•™æœ€è¿‘7å¤©æ•°æ®

é¢„åˆ›å»ºæœªæ¥3å¤©åˆ†åŒº

2. åˆ†æ¡¶ä¼˜åŒ–
   ä½¿ç”¨ HASH åˆ†æ¡¶

8ä¸ªåˆ†æ¡¶å‡åŒ€åˆ†å¸ƒæ•°æ®

åŸºäºä¸šåŠ¡é”®å€¼åˆ†å¸ƒ

3. Routine Load è°ƒä¼˜
   åˆé€‚çš„æ‰¹å¤„ç†å¤§å°

åˆç†çš„å¹¶å‘æ•°

é€‚å½“çš„æäº¤é—´éš”

