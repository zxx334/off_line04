#!/bin/bash

# SeaTunnel 动态数据同步脚本
# 用法: ./mysql_to_hive_sync.sh [选项]

# 默认参数值
JOB_MODE="BATCH"
PARALLELISM=2
SOURCE_TABLE="activity_rule"
TARGET_TABLE="bigdata_offline_v1_ws.ods_activity_rule"
PARTITION_FIELD="ds"
FILE_FORMAT="orc"
COMPRESSION="SNAPPY"

# 解析命令行参数
while [[ $# -gt 0 ]]; do
    case $1 in
        -m|--mode)
            JOB_MODE="$2"
            shift
            shift
            ;;
        -p|--parallelism)
            PARALLELISM="$2"
            shift
            shift
            ;;
        -s|--source-table)
            SOURCE_TABLE="$2"
            shift
            shift
            ;;
        -t|--target-table)
            TARGET_TABLE="$2"
            shift
            shift
            ;;
        -pf|--partition-field)
            PARTITION_FIELD="$2"
            shift
            shift
            ;;
        -ff|--file-format)
            FILE_FORMAT="$2"
            shift
            shift
            ;;
        -c|--compression)
            COMPRESSION="$2"
            shift
            shift
            ;;
        -h|--help)
            echo "Usage: $0 [options]"
            echo "Options:"
            echo "  -m, --mode <mode>            作业模式 (BATCH/STREAMING), 默认: BATCH"
            echo "  -p, --parallelism <num>      并行度, 默认: 2"
            echo "  -s, --source-table <table>   源表名, 默认: activity_rule"
            echo "  -t, --target-table <table>   目标表名, 默认: bigdata_offline_v1_ws.ods_activity_rule"
            echo "  -pf, --partition-field <field> 分区字段, 默认: ds"
            echo "  -ff, --file-format <format>  文件格式, 默认: orc"
            echo "  -c, --compression <type>     压缩格式, 默认: SNAPPY"
            echo "  -h, --help                   显示帮助信息"
            exit 0
            ;;
        *)
            echo "未知选项: $1"
            exit 1
            ;;
    esac
done

# 生成临时配置文件
CONFIG_FILE="/tmp/seatunnel_sync_$(date +%Y%m%d%H%M%S).conf"

cat > $CONFIG_FILE << EOF
env {
    parallelism = $PARALLELISM
    job.mode = "$JOB_MODE"
}

source {
    Jdbc {
        url = "jdbc:mysql://10.160.60.17:3306/realtime_v1?serverTimezone=GMT%2b8&useUnicode=true&characterEncoding=UTF-8&rewriteBatchedStatements=true&useSSL=false&allowPublicKeyRetrieval=true"
        driver = "com.mysql.cj.jdbc.Driver"
        connection_check_timeout_sec = 100
        user = "root"
        password = "root"
        query = "select id, activity_id, activity_type, condition_amount, condition_num, benefit_amount, benefit_discount, benefit_level, create_time, operate_time, DATE_FORMAT(NOW(), '%Y%m%d') as $PARTITION_FIELD from realtime_v1.$SOURCE_TABLE;"
    }
}

transform {

}

sink {
    Hive {
        table_name = "$TARGET_TABLE"
        metastore_uri = "thrift://cdh03:9083"
        hive.hadoop.conf-path = "/etc/hadoop/conf"
        save_mode = "overwrite"
        partition_by = ["$PART"]
        }
     }